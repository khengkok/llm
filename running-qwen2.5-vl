My configuration
2x RTX A6000 48GB
2x RTX A8000 48GB

pip install flash-attn --no-build-isolation

Need to set both GLOO_SOCKET_IFNAME and NCCL_SOCKET_IFNAME for it to work

Running cluster

bash run_cluster.sh \
                vllm/vllm-openai \
                172.20.170.19 \
                --head \
                /mnt/data/.cache/huggingface \
                -e VLLM_HOST_IP=172.20.170.19 -e GLOO_SOCKET_IFNAME=eno1 -e NCCL_SOCKET_IFNAME=eno1
vllm serve Qwen/Qwen2.5-VL-72B-Instruct -tp 2 -pp 2 --dtype half --max-model-len 16000  --max-num-seqs 1  --limit-mm-per-prompt image=1,video=0


## single-node with 2 GPUs running bnb4bit:

vllm serve unsloth/Qwen2.5-VL-72B-Instruct-bnb-4bit --max-num-seqs 1 --quantization bitsandbytes --load-format bitsandbytes  --enforce-eager --pipeline-parallel-size 2
